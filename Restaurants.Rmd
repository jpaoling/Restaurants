---
output: 
  rmarkdown::github_document:
    toc: TRUE
    toc_float: TRUE
title: "Restaurant Inspections"
---

```{r setup, include=FALSE}
library(tidyverse)
library(lubridate)
library(readxl)
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Introduction

In this data analysis project, I will try to use data on restaurant inspections to predict the number of days until the next inspection. Please note that this project has not been completed yet.

The data set I use contains information on restaurant inspections in New York City carried out by the Department of Health and Hygiene (DOHMH) between 2010 and 2017. The data set contains the following variables:

* CAMIS: a unique identifier for the restaurant

* DBA: name of (doing business as) the restaurant

* BORO: borough in which the restaurant is located

* BUILDING: building number for the restaurant

* STREET: street name at which the restaurant is located

* ZIPCODE: Zip code as per the (mailing) address of the restaurant

* PHONE: phone number

* CUISINE DESCRIPTION: cuisine of the restaurant

* INSPECTION DATE: date of inspection

* ACTION: action associated with the given inspection

* VIOLATION CODE: violation code associated with the given inspection

* VIOLATION DESCRIPTION: description that corresponds to violation code

* CRITICAL FLAG: indication if violation is critical or not

* SCORE: total score for a particular inspection

* GRADE: grade issued for the given inspection

* GRADE DATE: date when the current grade was issued to the restaurant

* RECORD DATE: The date when the extract was run to produce this data set 

* INSPECTION TYPE: The type of inspection. A combination of the program and inspection type

We read in the data:

```{r warning=FALSE}
(restaurants_raw <- read_excel("New_York_City_Restaurants.xlsx"))
```

For convenience, we rename the variables. 

```{r}
new_names <- c("id", "rest_name", "boro", "building", "street", "zipcode", 
               "phone", "cuisine_descr", "inspection_date", "action", 
               "violation_code", "violation_descr", "critical_flag", 
               "score", "grade", "grade_date", "record_date", 
               "inspection_type")
(names(restaurants_raw) <- new_names)
rm(new_names)
```


## 2. Exploratory Analysis

Let us turn to the exploration of the data..

### 2.1 Inspection Date

```{r}
restaurants_raw$inspection_date <- ymd(restaurants_raw$inspection_date) 
summary(restaurants_raw$inspection_date)
```

Apparently, there are some obeservations with an inspection date of "1900-01-01". Of course, these are wrong values. Let us look at these observations, in particular at the variables that relate to the grade of an inspection.

```{r}
restaurants_raw %>% 
  filter(inspection_date == "1900-01-01") %>% 
  select(action:inspection_type)
```

Values of all observations across all the variables relating to grading are missing. 

```{r}
restaurants_raw %>% 
  summarise(na_inspectionDate = round((sum(inspection_date == "1900-01-01")/n()), 4))
```

Those obervations amount to .03 % of all observations. For now, we will ignore those observations. 

```{r}
restaurants_raw <- restaurants_raw %>% 
  filter(!inspection_date == "1900-01-01")
```


### 2.2 Boros

Next, let us take a look at the distribution of 'Boro'.

```{r}
restaurants_raw$boro <- as.factor(restaurants_raw$boro)
levels(restaurants_raw$boro)[levels(restaurants_raw$boro) == "Missing"] <- NA
summary(restaurants_raw$boro)
```

```{r}
restaurants_raw %>% 
  group_by(boro) %>% 
  summarize(n = n_distinct(id)) %>% 
  ggplot(aes(x = reorder(boro, -n), y = n)) +
  geom_bar(stat = "identity") + 
  theme(axis.text.x = element_text(angle=60, hjust=1))
```

Most observations are from Manhattan.


### 2.3 Actions taken

```{r}
levels(as.factor(restaurants_raw$action))
```

We convert it into a factor and (re)name its levels for convenience:

```{r}
restaurants_raw$action <- as.factor(restaurants_raw$action)
levels(restaurants_raw$action) <- c("Closed", "ReClosed", "ReOpened", "NoViol", "YesViol")
summary(restaurants_raw$action)
```



```{r}
(action_df <- restaurants_raw %>% 
  group_by(action) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n)))

action_df %>% 
  ggplot(aes(reorder(action, -n), n)) +
  geom_bar(stat = "identity") +
  xlab("Action taken by DOHMH") 
```

In the vast majority of inspections violations were cited. Among these, a very small number leads to restaurant closures. 


### 2.7 Violation types

Next, we will consider the different types of violations recorded.

```{r}
restaurants_raw$violation_code <- as.factor(restaurants_raw$violation_code)

restaurants_raw %>% 
  group_by(violation_code) %>% 
  summarise(number = n()) %>% 
  mutate(rank = rank(desc(number))) %>% 
  filter(rank <= 10) %>% 
  arrange(rank)
```

10F (general violation pertaining to non-food contact surfaces) is the most common violation type. followed by 08A (facility not vermin proof), 04L (Evidence of mice).

Here is a quick plot of the distribution:

```{r}
restaurants_raw %>% 
  ggplot(aes(x = violation_code)) +
  geom_bar() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  xlab("Violation code")
```

To get a better sense of what is going on, we group the values in the range of violation_code into broader categories. To do this, we use information from the provided by the authorities. Accordingly, violations are either scored or unscored. Among scored violations, we have to distinguish between critical and general violations.

```{r}
violations <- restaurants_raw$violation_code
patterns <- list(
  violations %in% str_c("02", LETTERS[1:10]) ~ "crit_food_temperature",
  violations %in% str_c("03", LETTERS[1:7]) ~ "crit_food_source",
  violations %in% str_c("04", LETTERS[1:15]) ~ "crit_food_protection",
  violations %in% str_c("05", LETTERS[1:9]) ~ "crit_facility_design",
  violations %in% str_c("06", LETTERS[1:9]) ~ "crit_personal_hygiene",
  violations == "07A" ~ "crit_other",
  violations %in% str_c("08", LETTERS[1:3]) ~ "gen_vermin",
  violations %in% str_c("09", LETTERS[1:3]) ~ "gen_food_source",
  violations %in% str_c("10", LETTERS[1:10]) ~ "gen_facility_manage",
  violations == "99B" ~ "gen_other",
  !is.na(violations) ~ "not_scored"
  )
# New variable violation_group:
restaurants_raw <- 
  restaurants_raw %>% 
  mutate(violation_group = case_when(!!!patterns))
rm(patterns)
rm(violations)
```

Here is bar plot displaying the distribution
```{r}
restaurants_raw %>% 
  group_by(violation_group) %>% 
  filter(!is.na(violation_group)) %>% 
  summarize(n = n()) %>% 
  ggplot(aes(reorder(violation_group, -n), n)) +
  geom_bar(stat = "identity", fill = "blue") +
  theme(axis.text.x = element_text(angle=60, hjust=1))
```

Some categories barely contain any observations. For the time being, we will keep the chosen binning. We are going to revisit this point in the context of feature engineering.

Here is the distribution of violation code again. This time we incorporate the variable violation group.

```{r}
restaurants_raw %>% 
  filter(!is.na(violation_group)) %>% 
  ggplot(aes(x = violation_code, fill = violation_group)) +
  geom_bar() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank())
```

### 2.8 Inspection types

The variable inspection type takes on 34 distinct values:

```{r}
restaurants_raw %>% 
     summarise(n_distinct(inspection_type))
```

These are the values:

```{r}
restaurants_raw %>% 
  group_by(inspection_type) %>% 
  summarise()
```

We collapse these values into a smaller range:

```{r}
restaurants_raw$inspection_type2 <-  restaurants_raw %>% 
  select(inspection_type) %>% 
  separate(inspection_type, into = c("before_slash", "after_slash"), sep = " / ") %>% 
  transmute(after_slash = str_replace_all(after_slash, fixed(" "), fixed(""))) %>% 
  transmute(inspection_type2 = str_replace_all(after_slash, fixed("-i"), fixed("I"))) %>% 
  .$inspection_type2

unique(restaurants_raw$inspection_type2)
```

Here a display of the distribution:

```{r}
restaurants_raw %>% 
  group_by(inspection_type2) %>% 
  summarise(n = n()) %>% 
  ggplot(aes(reorder(as.factor(inspection_type2), -n), n)) +
  geom_bar(stat = "identity", color = "orange") +
  xlab("Inspection type") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Again, there a are categories that are 'almost empty'. The vast majority of observations are initial and re-inspections:

```{r}
restaurants_raw %>% 
  group_by(inspection_type2) %>% 
  summarise(n = n(), prop = round(n/nrow(restaurants_raw), 5)) %>% 
  arrange(desc(n))
```

For later purposes, we contruct a dummy variable for the category 'InitialInspection'.

```{r}
restaurants_raw$dummy_InitialInspection <- 
  ifelse(restaurants_raw$inspection_type2 == "InitialInspection", 1, 0)
names(restaurants_raw)
```


### 2.9 Grade

```{r}
restaurants_raw %>% 
  group_by(grade) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n))
```

There is a massive amount of NA's. We are going to investigate how the number of NAs for ‘grade’ relates to ‘score’ and ‘inspection_type.’ More precisely, we know that on initial inspections no grade is issued, if the corresponding score is above 14. It seems plausible that this would lead to a value of NA for grade.

```{r}
restaurants_raw %>% 
  select(inspection_type2, score, grade) %>% 
  filter(inspection_type2 == "InitialInspection", score > 14) %>%
  group_by(grade) %>% 
  summarise(n = n())
```

So about 73 % of the missing values are due to a score of 14 or higher. Furthermore, out of the 1915 observations with value ‘Not yet graded’, 1548 are the result of a high score (above 13) in the initial inspection. We will recode these NA’s to “Not Yet Graded” to reduce the number of missing values for ‘grade’.

```{r}
# Recode NA's with inspection type = 'InitialInspection' and 'score' > 14 to "Not Yet Graded":
restaurants_raw <- restaurants_raw %>% 
  mutate(grade = case_when(
    is.na(.$grade) & 
      .$inspection_type2 == "InitialInspection" &
      .$score > 14 ~ "Not Yet Graded",
    TRUE ~ grade
  ))
```

We have reduced the number of NA's significantly:

```{r}
restaurants_raw %>% 
  summarise(prop_na = round(mean(is.na(grade)), 2),
            n_not_graded = sum(grade == "Not Yet Graded", na.rm = T))
```

Here is the distribution of the proportion of inspections with an NA for grade per restaurant:

```{r}
restaurants_raw %>% 
  group_by(id, inspection_date) %>% 
  summarise(prop_gradeNA = mean(is.na(grade))) %>% 
  ggplot(aes(x = prop_gradeNA)) + 
  geom_histogram(bins = 30) + 
  xlab("proportion of NA's for inspection grade per restaurant")
```

It seems that for most restaurants there is no inspection with a missing value for  On the other hand, there are some restaurants for whom all values for grade are NA.

```{r}
restaurants_raw %>% 
  group_by(id, inspection_date) %>% 
  summarise(prop_gradeNA = round(mean(is.na(grade)), 3)) %>% 
  ungroup() %>% 
  group_by(prop_gradeNA) %>% 
  summarise(proportion_of_restaurants = round(n()/nrow(.), 3)) %>% 
  arrange(desc(proportion_of_restaurants))
```


As we did before, we are going to construct dummy variables, this time for the different levels of grade. We'll use "Z" as base category: 

```{r}
temp_index <- restaurants_raw$grade == "Not Yet Graded"
restaurants_raw$grade[temp_index] <- "NotYetGraded"
rm(temp_index)
for(level in unique(restaurants_raw$grade)){
  
  if (is.na(level) | level == "Z") {
    next
  } else {
    restaurants_raw[paste("dummy", level, sep = "_")] <- 
      ifelse(!is.na(restaurants_raw$grade) & 
               restaurants_raw$grade == level, 1, 0)
  }
  
}

rm(level)
names(restaurants_raw)
```

### 2.10 Score

Let us turn to 'score'.

```{r}
summary(restaurants_raw$score)
```

There are 19514 NA’s. We know that there are 16530 observations that refer to violations that are not scored:

```{r}
restaurants_raw %>% 
  group_by(violation_group) %>% 
  summarise(n = n()) %>% 
  filter(violation_group == "not_scored")    
```


These observations are expected to have NA for ‘score’:
```{r}
restaurants_raw %>% 
  select(violation_group, score) %>% 
  filter(violation_group == "not_scored") %>% 
  summarise(n = n(), n_na_score = sum(is.na(score)), prop_na_score = round(n_na_score/n, 2))
```

Hence, these observations account for 82 % of all of the 19514 NA’s for ‘score’. We will recode them to have a score of 0:

```{r}
# Recode score NA's for which violation group is 'not_scored' to 0:
restaurants_raw$score[restaurants_raw$violation_group == "not_scored"] <- 0
# Remaining NA's:
sum(is.na(restaurants_raw$score))
```

What about these remaining 3428 missing values for ‘score’? Let us consider the relationship with violation group:

```{r}
restaurants_raw %>% 
  select(violation_group, score) %>% 
  filter(is.na(violation_group)) %>%  
  summarise(n = n(), n_na_score = sum(is.na(score)))
```

Hence, the rest of the NA’s for score are associated with NA’s on ‘violation_group’. So let us turn to the NA’s for the variable ‘violation_group’. One cause for an NA here may be that on a given inspection, there was no violation at all. So what is the number of NA's for score among observations that do not exhibit a violation?

```{r}
restaurants_raw %>% filter(action == "NoViol") %>% 
  summarise(scoreNAs_among_noViolation = sum(is.na(score)))
```

Apparently, almost all of 3428, namely 3426, can be assumed to be the result of a non-violation. So now, there are only 2 missing values for score left. We’ll assign them the median value of the non-Na scores:

```{r}
restaurants_raw$score[is.na(restaurants_raw$score)] <-
  median(restaurants_raw$score[!is.na(restaurants_raw$score)])
sum(is.na(restaurants_raw$score))
```

## 3. Predicting the number of days until the next inspection

### 3.1 Split into training and test data

As a first step, we will divide our data set into a training and a test data set, putting 2/3 of the restaurants into the training set.

```{r}
set.seed(1)
train_ids <- sample(unique(restaurants_raw$id), 0.6*length(unique(restaurants_raw$id)))
test_ids <- setdiff(unique(restaurants_raw$id), train_ids) 
```

Next, let us see if the distributions of the target feature in training and test data are similar:

```{r}
restaurants_raw %>% 
  select(id, inspection_date) %>% 
  group_by(id, inspection_date) %>% 
  arrange(inspection_date) %>% 
  summarise() %>% 
  mutate(difference = lead(inspection_date) - inspection_date) %>%
  filter(!is.na(difference)) %>% 
  mutate(group = ifelse(id %in% train_ids, "Training", "Test")) %>% 
  ggplot(aes(as.numeric(difference))) +
  geom_histogram(bins = 30) +
  xlab("Days until next inspection") +
  facet_grid(. ~ group) 
```

The distribution of the target seems reasonably similar across training and test data. Now, we'll split the data set into training and test data:


```{r}
# Training data
train_df <- restaurants_raw %>% 
  filter(id %in% train_ids)
# Test data
test_df <- restaurants_raw %>% 
  filter(id %in% test_ids) 
```


So now, we remove the original data set and test data from the workspace and save the latter to a file:

```{r}
write.csv(test_df, "test_restaurants.csv")
rm(restaurants_raw)
rm(test_df)
```


### 3.2

```{r}
train_df %>% 
  select(id, inspection_date, inspection_type2, score, grade,
         dummy_A, dummy_B, dummy_C, dummy_NotYetGraded, dummy_P, dummy_Z) %>% 
  group_by(id, inspection_date) %>% 
  arrange(id, inspection_date) %>% 
  summarise_at(c("grade", "score", "inspection_type2", 
                 "dummy_A", "dummy_B", "dummy_C",
                 "dummy_NotYetGraded", "dummy_P", "dummy_Z"), 
               .funs = list(first)) %>% 
  mutate(days_until_next = lead(inspection_date) - inspection_date)
```
















