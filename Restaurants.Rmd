---
output: 
  html_notebook:
    toc: TRUE
    toc_float: TRUE
title: "Restaurant Inspections"
---

The data set at hand contains information on restaurant inspections in New York City carried out by the Department of Health and Hygiene (DOHMH).


# **Exploration**

```{r setup}
library(tidyverse)
```


## Data Import

```{r warning=FALSE}
library(readxl)
restaurants_raw <- read_excel("New_York_City_Restaurants.xlsx")
restaurants_raw
```


## Variables

* CAMIS: a unique identifier for the restaurant

* DBA: name of (doing business as) the restaurant

* BORO: borough in which the restaurant is located

* BUILDING: building number for the restaurant

* STREET: street name at which the restaurant is located

* ZIPCODE: Zip code as per the (mailing) address of the restaurant

* PHONE: phone number

* CUISINE DESCRIPTION: cuisine of the restaurant

* INSPECTION DATE: date of inspection

* ACTION: action associated with the given inspection

* VIOLATION CODE: violation code associated with the given inspection

* VIOLATION DESCRIPTION: description that corresponds to violation code

* CRITICAL FLAG: indication if violation is critical or not

* SCORE: total score for a particular inspection

* GRADE: ...

* GRADE DATE: date when the current grade was issued to the restaurant

* RECORD DATE: The date when the extract was run to produce this data set 

* INSPECTION TYPE: The type of inspection. A combination of the program and inspection type


```{r}
names(restaurants_raw)
```

```{r}
new_names <- c("id", "rest_name", "boro", "building", "street", "zipcode", "phone", "cuisine_descr",
                            "inspection_date", "action", "violation_code", "violation_descr",
                            "critical_flag", "score", "grade", "grade_date", "record_date", "inspection_type")
names(restaurants_raw) <- new_names

# Rename variables
names(restaurants_raw)
```


## Structure of data set

```{r}
glimpse(restaurants_raw)
```



## Univariate analysis

### Number of different restaurants

```{r}
# Number of different restaurants
restaurants_raw %>% 
  summarise(n_rest = n_distinct(id))
```

There are 26438 different restaurants. Next we check whether restaurant id's are associated with unique names:

```{r}
# First check for NA's
nrow(restaurants_raw %>% 
  select(id) %>% 
  group_by(id) %>% 
  summarise(n_na = sum(is.na(id))) %>% 
  filter(n_na != 0))
```
There are no missing values for id.

```{r}
## Check if restaurant ids map to unique restaurant names
# Are there any id's that map onto more than or less than one single name
nrow(restaurants_raw %>% 
  select(id, rest_name) %>% 
  group_by(id) %>% 
  summarise(n = n_distinct(rest_name)) %>% 
  filter(n != 1)) 
```

It seems that each id is associated with a unique restaurant name, as one would expect. 

### Number of inspections per restaurant

Heavily skewed to the right. 

```{r}
restaurants_raw %>% 
  group_by(id) %>% 
  summarize(n = n()) %>% 
  ggplot(aes(x = n)) +
  geom_density(fill = "orange") +
  xlab("Number of inspections")
```


### Boros

```{r}
restaurants_raw$boro <- as.factor(restaurants_raw$boro)

levels(restaurants_raw$boro)[levels(restaurants_raw$boro) == "Missing"] <- NA
summary(restaurants_raw$boro)
```


```{r}
boros <- restaurants_raw %>% 
  group_by(boro) %>% 
  summarize(n = n_distinct(id)) %>% 
  arrange(desc(n))
boros
```

```{r}
boros %>%  
  ggplot(aes(x = reorder(boro, -n), y = n)) +
  geom_bar(stat = "identity", color = "blue") +
  xlab("boro")
```

### Inspection date


```{r}
# Load lubridate package
library(lubridate)

# Convert date columns of data:
restaurants_raw$inspection_date <- ymd(restaurants_raw$inspection_date) 
```



```{r}
str(restaurants_raw$inspection_date)
summary(restaurants_raw$inspection_date)
```

There are some observations with inspection_date "1900-01-01"!

```{r}
restaurants_raw %>% 
  filter(inspection_date == "1900-01-01")
```

It seems that those are inspections that didn't take place. Therefore we will treat those values as NAs.

```{r}
# Replace these values in inspection_date with NA's:
index_inspec_val1900 <- restaurants_raw$inspection_date == "1900-01-01"
sum(index_inspec_val1900)

restaurants_raw$inspection_date[index_inspec_val1900] <-  NA
sum(is.na(restaurants_raw$inspection_date))
```

In the following we'll exclude those observations from the data set:

```{r}
# Exclusion of observations with no value of inspection date
restaurants_raw <- restaurants_raw %>% 
  filter(!is.na(inspection_date))

nrow(restaurants_raw)
```

Write new cleaned up data set to file

```{r}
# write.csv(restaurants_raw, "restaurants_clean.csv")
```



### Cuisine description

```{r}
restaurants_raw$cuisine_descr <- as.factor(restaurants_raw$cuisine_descr)
str(restaurants_raw$cuisine_descr)
unique(restaurants_raw$cuisine_descr)

# Relabel level "Not Listed/Not Applicable"
sum(restaurants_raw$cuisine_descr == "Not Listed/Not Applicable")
levels(restaurants_raw$cuisine_descr)[levels(restaurants_raw$cuisine_descr) == "Not Listed/Not Applicable"] <- NA
sum(is.na(restaurants_raw$cuisine_descr))

# Relabel level "CafÃƒÂ©/Coffee/Tea" which is at position 14 in levels vector
cuis_ind <- levels(restaurants_raw$cuisine_descr) == levels(restaurants_raw$cuisine_descr)[14]
levels(restaurants_raw$cuisine_descr)[cuis_ind] <- "Coffee_Tea"
levels(restaurants_raw$cuisine_descr)

# Relabel level "Latin (..." into "Latin"
levels(restaurants_raw$cuisine_descr)[levels(restaurants_raw$cuisine_descr) == "Latin (Cuban, Dominican, Puerto Rican, South & Central American)"] <- "Latin"

levels(restaurants_raw$cuisine_descr)
```

```{r}
# Visualization
restaurants_raw %>% 
  group_by(cuisine_descr) %>% 
  summarise(n = n_distinct(id)) %>% 
  ggplot(aes(x = reorder(cuisine_descr, -n), y = n)) +
  geom_bar(stat = "identity") +
  xlab("Cuisine") +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank())

restaurants_raw %>% 
  group_by(cuisine_descr) %>% 
  summarise(n = n_distinct(id)) %>%
  arrange(desc(n))
```

The most common categories of restaurants are "American" and "Chinese" followed by "Café", "Other", "Pizza" , "Italian", "Mexican", "Japanese" and "Latin".


### Actions taken

This variable takes on the following values:

```{r}
levels(as.factor(restaurants_raw$action))
```

We convert it into a factor and (re)name its levels for convenience:

```{r}
restaurants_raw$action <- as.factor(restaurants_raw$action)
levels(restaurants_raw$action) <- c("Closed", "ReClosed", "ReOpened", "NoViol", "YesViol")
summary(restaurants_raw$action)
```



```{r}
(action_df <- restaurants_raw %>% 
  group_by(action) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n)))

action_df %>% 
  ggplot(aes(reorder(action, -n), n)) +
  geom_bar(stat = "identity") +
  xlab("Action taken by DOHMH") 
```

In the vast majority of inspections violations were cited. Among these, a very small number leads to restaurant closures. 




### Violation types

Next we will take a look at violation types. 

```{r}
# Conversion into factor:
restaurants_raw$violation_code <- as.factor(restaurants_raw$violation_code)
summary(restaurants_raw$violation_code)
```

What are ten most frequent violations?

```{r}
# Overall
restaurants_raw %>% 
  group_by(violation_code) %>% 
  summarise(number = n()) %>% 
  mutate(rank = rank(desc(number))) %>% 
  filter(rank <= 10) %>% 
  arrange(rank)
```
10F (general violation pertaining to non-food contact surfaces) is the most common violation type.  followed by 08A (facility not vermin proof), 04L (Evidence of mice).

Next, here is a quick plot of the distribution:

```{r}
restaurants_raw %>% 
  ggplot(aes(x = violation_code)) +
  geom_bar() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank())
```


To get a better sense of what is going on, we group the values in the range of violation_code into broader categories. To do this, we use information from the  provided by the authorities. Accordingly, violations are either scored or unscored. Among scored violations, we have to distinguish between critical and general violations. 


```{r}
violations <- restaurants_raw$violation_code

patterns <- list(
  violations %in% str_c("02", LETTERS[1:10]) ~ "crit_food_temperature",
  violations %in% str_c("03", LETTERS[1:7]) ~ "crit_food_source",
  violations %in% str_c("04", LETTERS[1:15]) ~ "crit_food_protection",
  violations %in% str_c("05", LETTERS[1:9]) ~ "crit_facility_design",
  violations %in% str_c("06", LETTERS[1:9]) ~ "crit_personal_hygiene",
  violations == "07A" ~ "crit_other",
  violations %in% str_c("08", LETTERS[1:3]) ~ "gen_vermin",
  violations %in% str_c("09", LETTERS[1:3]) ~ "gen_food_source",
  violations %in% str_c("10", LETTERS[1:10]) ~ "gen_facility_manage",
  violations == "99B" ~ "gen_other",
  !is.na(violations) ~ "not_scored"
  )

# New variable violation_group:
restaurants_raw <- 
  restaurants_raw %>% 
  mutate(violation_group = case_when(!!!patterns))

rm(patterns)
rm(violations)
```

As a sanity check, verify that the number of NAs in violation_group and violation_code is the same:

```{r}
sum(is.na(restaurants_raw$violation_group)) == sum(is.na(restaurants_raw$violation_code))
```

Distribution of violation_group:

```{r}
restaurants_raw %>% 
  group_by(violation_group) %>% 
  filter(!is.na(violation_group)) %>% 
  summarize(n = n()) %>% 
  ggplot(aes(reorder(violation_group, -n), n)) +
  geom_bar(stat = "identity", fill = "blue")
```


Let us look at the distribution of violation_code again, now using the information which group a given violation belongs:

```{r}
# Overall
restaurants_raw %>% 
  filter(!is.na(violation_group)) %>% 
  ggplot(aes(x = violation_code, fill = violation_group)) +
  geom_bar() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank())

```

... and by boro:

```{r}
# By boro
restaurants_raw %>% 
  filter(!is.na(boro), !is.na(violation_group)) %>% 
  ggplot(aes(x = violation_code, fill = violation_group)) +
  geom_bar() +
  facet_wrap(~ boro) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank())
```








### Inspection type

```{r}
str(restaurants_raw$inspection_type)
summary(as.factor(restaurants_raw$inspection_type))
```

Check for NAs:

```{r}
summary(restaurants_raw$inspection_type)
sum(!is.na(restaurants_raw$inspection_type))
```

We'll create new variable inspection_type2 by collapsing the range into a smaller set of values.

```{r}
restaurants_raw$inspection_type2 <-  restaurants_raw %>% 
  select(inspection_type) %>% 
  separate(inspection_type, into = c("before_slash", "after_slash"), sep = " / ") %>% 
  transmute(after_slash = str_replace_all(after_slash, fixed(" "), fixed(""))) %>% 
  transmute(inspection_type2 = str_replace_all(after_slash, fixed("-i"), fixed("I"))) %>% 
  .$inspection_type2

unique(restaurants_raw$inspection_type2)
```


Let us construct dummy variables for the categories above which will come in handy, once we get to the task of prediction:

```{r}
for(level in unique(restaurants_raw$inspection_type2)){
  restaurants_raw[paste("dummy", level, sep = "_")] <- 
    ifelse(restaurants_raw$inspection_type2 == level, 1, 0)
}
names(restaurants_raw)
```


### Grade and Score

Grades:

```{r}
restaurants_raw %>% 
  group_by(grade) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n))
         
```


Relationship between grade and inspection date:

```{r}
restaurants_raw %>% 
  select(grade, inspection_date) %>% 
  filter(!is.na(grade)) %>%
  separate(inspection_date, into = c("year", "month", "day")) %>% 
  group_by(year) %>% 
  summarise(prop_pending = round(mean(grade %in% c("P","Z")), 3),
            prop_notYetGraded = round(mean(grade == "Not Yet Graded"), 3))
```

The proportion of grades pending and not yet graded is higher for earlier inspections, which is not surprising. 

Next, we'll look at how the number of NAs for 'grade' relates to the number of NAs for 'inspection_type.' As a reminder, above we saw that there are 187702 missing values for 'grade' overall.

```{r}
restaurants_raw %>% 
  select(inspection_type2, score, grade) %>% 
  filter(inspection_type2 == "Initial Inspection", score > 14) %>%
  group_by(grade) %>% 
  summarise(n = n())
  
```

So about 73 % of the missing values are due to a score of 14 or higher. Furthermore, out of the 1915 observations with value 'Not yet graded', 1548 are the result of a high score (above 13) in the initial inspection.

Let us turn to 'score':

```{r}
summary(restaurants_raw$score)
```

There are 19514 NA's. We know that there are 16530 observations that refer to violations that are not scored. These observations are expected to have NA for 'score':

```{r}
restaurants_raw %>% 
  select(violation_group, score) %>% 
  filter(violation_group == "not_scored") %>% 
  summarise(n = n(), n_na_score = sum(is.na(score)), round(n_na_score/n, 2))
  
```

There are 16530 observations that belong to the 'not_scored' violation group. Indeed, the vast majority of those, namely 16086, has a missing score value (97 %). These observations account for 82 % of all of the 19514 NA's for 'score':

```{r}
round(16086/19514, 2)
```

We will recode their score to 0:

```{r}
# Recode score NA's for which violation group is 'not_scored' to 0:
restaurants_raw$score[restaurants_raw$violation_group == "not_scored"] <- 0
# Remaining NA's:
sum(is.na(restaurants_raw$score))
```


What about the remaining 18 %, the 3428 other missing values for 'score'?

```{r}
restaurants_raw %>% 
  select(violation_group, score) %>% 
  filter(is.na(violation_group)) %>%  
  summarise(n = n(), n_na_score = sum(is.na(score)))
    
```

Hence, the rest of the NA's for score are associated with NA's on 'violation_group'. 

So let us turn to the NA's for the variable 'violation_group'. One cause for an NA here may be that on a given inspection, there was no violation at all.

```{r}
# Check for NA's for violation group among observations where there was no violation on the respective inspection:
restaurants_raw %>% filter(action == "NoViol") %>% 
  summarise(violNAs_among_noViolation = sum(is.na(violation_group)), 
            scoreNAs_among_noViolation = sum(is.na(score)))
```

We see that almost all of the remaining NA's for score are due to the absence of violations on the respective inspection. We will recode these scores accordingly, by assigning them the value 0 as well:

```{r}
restaurants_raw$score[restaurants_raw$action == "NoViol" & is.na(restaurants_raw$score)] <- 0
sum(is.na(restaurants_raw$score))
```

So now, there are only 2 missing values for score left. We'll assign them the median value of the non-Na scores:

```{r}
restaurants_raw$score[is.na(restaurants_raw$score)] <-
  median(restaurants_raw$score[!is.na(restaurants_raw$score)])
sum(is.na(restaurants_raw$score))
```



Here is a plot of the distribution of 'score' of all non-NA observations:

```{r}
restaurants_raw %>% 
  ggplot(aes(x = score)) +
  geom_histogram(bins = 25)

restaurants_raw %>% 
  ggplot(aes(x = 1, y = score)) +
  geom_boxplot()
```

It is also sensible to change the NA's for violation group where there was no violation. Let us also see how many NA's for violation group there are overall:

```{r}
restaurants_raw %>% 
  summarise(NA_overall = sum(is.na(violation_group)), 
            NA_noViol = sum(is.na(violation_group) & action == "NoViol"))
```

We will the name the new category "None":

```{r}
# 
temp <- restaurants_raw$action == "NoViol" & is.na(restaurants_raw$violation_group)
restaurants_raw$violation_group[temp] <- "None"
unique(restaurants_raw$violation_group)
```


For later use, we construct dummy variables for the different violation groups:

```{r}
for(level in unique(restaurants_raw$violation_group)){
  restaurants_raw[paste("dummy", level, sep = "_")] <- 
    ifelse(restaurants_raw$violation_group == level, 1, 0)
}
names(restaurants_raw)
```


### Critical flag

Conversion into factor and renaming of levels:

```{r}
restaurants_raw$critical_flag <- as.factor(restaurants_raw$critical_flag)
summary(as.factor(restaurants_raw$critical_flag))
levels(restaurants_raw$critical_flag) <- c("Critical", "Not_Applicable", "Not_Critical")
levels(restaurants_raw$critical_flag)

```

Recode levels:

```{r}
summary(as.factor(restaurants_raw$critical_flag))
levels(restaurants_raw$critical_flag) <- c("Critical", "Not_Applicable", "Not_Critical")
levels(restaurants_raw$critical_flag)
```






## Proportion of critical flag conditional on cuisine

Critical flag by cuisine: 

```{r}
restaurants_raw %>% 
  group_by(cuisine_descr) %>% 
  summarise(n = n_distinct(id)) %>%
  arrange(desc(n)) 
```

including only 7 most frequent cuisines...

```{r}
restaurants_raw %>% 
  filter(cuisine_descr %in% c("American", "Chinese", 
                              "Coffee_Tea", 
                              "Other", "Pizza", 
                              "Italian", "Mexican",
                              "Japanese", 
                              "Latin",
                              "Bakery")) %>% 
  ggplot(aes(x = cuisine_descr, fill = critical_flag)) +
  geom_bar(position = "fill")
```

The proportion of critical flag does not vary with cuisine. In the category "Other" there is a large proportion of observations labeled "Not Applicable".



# **Prediction of time between inspections**  

## Time passed between inspections

```{r}
library(lubridate)
restaurants_raw$inspection_date <- ymd(restaurants_raw$inspection_date) 
```

As a first step, we will divide our data set into a training and a test data set, putting 2/3 of the restaurants into the training set.

```{r}
set.seed(1)
train_ids <- sample(unique(restaurants_raw$id), 0.6*length(unique(restaurants_raw$id)))
test_ids <- setdiff(unique(restaurants_raw$id), train_ids) 
```

Then we construct the training data set:

```{r}
# Training data
train_df <- restaurants_raw %>% 
  filter(id %in% train_ids)
```

The remaining restaurants are saved into a file and stored away. Furthermore we will remove our initial data set from the workspace:

```{r}
restaurants_raw %>% 
  filter(id %in% test_ids) %>% 
write.csv("test_restaurants.csv")
rm(restaurants_raw)
```


Next, We will construct a table containing the difference between inspections and the total score for a given inspection:

```{r}
# Data frame containing restaurant id, inspection date, total score and time between inspections
train_diff_score <- train_df %>% 
  select(id, inspection_date, score) %>% 
  group_by(id, inspection_date) %>%
  arrange(inspection_date) %>%
  summarise(score_total = sum(score, na.rm = TRUE)) %>% 
  mutate(difference = lead(inspection_date) - inspection_date) %>% 
  ungroup()

train_diff_score %>% 
  filter(!is.na(difference)) %>% 
  ggplot(aes(x = as.numeric(difference))) +
  geom_histogram(bins = 30) +
  xlab("Number of days between inspections")
```

Next, we construct a data frame containing id, inspection date and the dummy variables for inspection type and violation group: 

```{r}
# We exclude the dummy variable 'dummy_NA' which signifies an unknown violation group for a recorded violation on a given inspection for a given restaurant
train_inspec_viol <- train_df %>% 
  select(id, inspection_date, starts_with("dummy"), -dummy_NA)
names(train_inspec_viol)
```

Now, we will transform the data frame 'train_violations' so that each row corresponds to the inspection on the given date and at the given restaurant. For each row and each violation group the corresonding entry in the table signifies whether the respective violation group was recorded. 

```{r}
# Tranformation of sample_violations:
train_inspec_viol <- train_inspec_viol %>% 
  group_by(id, inspection_date) %>% 
  summarise_at(vars(starts_with("dummy")), ~ ifelse(sum(.) != 0, 1, 0)) %>% 
  arrange(id, inspection_date) %>% 
  ungroup()
train_inspec_viol
```

We'll join the table sample_violations with the table 'train_diff_score', created earlier, for convenience reproduced below:

```{r}
train_diff_score
```

They have a shared key given by the pair (id, inspection_date). Hence we will join those tables to obtain the following data frame:

```{r}
train_df_complete <- train_diff_score %>% 
  inner_join(train_inspec_viol, by = c("id", "inspection_date")) %>% 
  filter(!is.na(difference)) 
train_df_complete
```

Note that we have omitted the rows with an NA for difference. Since inspection date had no NA's, the NA's for difference are exactly the ones resulting from the manner in which the variable was created. More precisely, for each restaurant, the last and only the last inspection is NA. Because there is no subsequent inspection, there is no loss of relevant information when removing that observation. 

# Baseline Model

First we load the packages 'rpart' and 'rpart.plot'

```{r echo=FALSE}
# install.packages("rpart")
# install.packages("rpart.plot")
library(rpart)
library(rpart.plot)
```
 
The first model will try to reproduce the static rules governing the inspection procedure. We will try model the time between inspections using 'score' and the dummy variables for inspection type:

```{r}
train_df_1 <- train_df_complete %>% 
  select(difference, score_total, ends_with("Inspection"))
train_df_1
```

```{r}
m1 <- rpart(difference ~ ., data = train_df_1, method = "anova")
m1
```

```{r}
rpart.plot(m1, type = 3, digits = 3, fallen.leaves = TRUE)
```



















